\chapter[Dirichlet-multinomial score: evaluation]{A Dirichlet-multinomial score: evaluation}\label{C:2D}

The Dirichlet-multinomial score (DM-Score) developed in Chapter \ref{C:1D} is evaluated in this chapter. 

The performance of the score in identifying astronomicla sources is evaluated against simulated data as well as against subimages from two large astronomical images. Performance is compared to a ground truth catalogue constructed using the source detection software BLOBCAT \cite{hales2012blobcat} with manual postprocessing by an astronomer. The Dirichlet bin border-softening technique, described in Chapter \ref{C:BIN} is employed, and results obtained using this technique are compared to ``hard" binning strategies.


\section{Methods}

The Dirichlet-multinomial Score was applied to real and simulated data, in order to test whether peaks in the score corresponded to locations and sizes of sources (i.e., non-background regions of the images). The method was tested using hard-bordered and soft-bordered test regions defined by a Gaussian curve (one dimensional data) or Gaussian ellipse (two dimensional data). Equal occupancy and equal width histogram binning strategies (as described in Section \ref{sec:binning-strategies} in Chapter \ref{C:BIN}) were employed, and the Dirichlet-border ``softening" of both types of bin borders (Section \ref{sec:dirichlet-borders}, Chapter \ref{C:BIN}) was also used. Gradient ascent was performed to find peaks in the DM-Score. A potential improvement to the DM-Score (background compensation) is described.

\subsubsection{Outline of the procedure}

\begin{enumerate}
\item{Given:}
  \begin{itemize}
  \item{data (real or simulated),}
  \item{a weighting function $W^{\theta}$ for test regions, and}
  \item{a binning strategy (equal width, Dirichlet equal width, equal occupancy, or Dirichlet equal occupancy)}
  \end{itemize}
\item{Exhaustively calculate the DM-Score over a range of values for parameters $\theta$ (optional);}
\item{Perform gradient-ascent to locate sources in the data (iteratively removing found sources from the data); and}
\item{Compare the parameters of found sources against those of actual sources to evaluate performance.}
\end{enumerate}

Each of these steps is described in more detail below.

\subsection{Parameters}

\subsubsection{Data: one dimensional}\label{sec:1d-methods-data}
Both real and simulated data were used in early exploration of the methods described in this chapter; simulated data was used for evaluation.

Real data comprised $1 \times X$ ``slices" through astronomical images at some $y$-position. An example of these data is shown in Figure \ref{fig:1d-real}. 

\begin{figure}
\centering
\includegraphics[width=1.0\textwidth]{IMAGES/1D-line.png}
\caption[One dimensional data from a two dimensional image]{\textbf{One dimensional data.} A ``slice" through an astronomical image. The image is shown at top-left, and at top-right with contrast adjusted to see sources. The slice through the data is shown as a red line in both images. At bottom, a plot of $x$-position by pixel intensity is shown. Image source: \cite{saripalli2012atlbs,subrahmanyan2010atlbs}.}
\label{fig:1d-real}
\end{figure}

Simulated data were created by generating three ``sources" and then overlaying the sources with Gaussian noise. In each simulated image, one source was generated using the Gaussian function (where $m$ is an $x$-position and $\sigma$ an approximate half-width; $A$ controls the height of the peak):
\begin{align}
A \exp\left( -\frac{(x-m)^2}{2\sigma^2} \right) \label{eq:1d-gaussian-fn} 
\end{align}
with noise added such that faint sources had lower than average variance. Two sources were generated by a skewed generalised Gaussian \cite{nadarajah2005generalized}:
\begin{align}
\left[\frac{\beta}{2 \alpha \Gamma(\frac{1}{\beta})} 
\exp\left( -\left(\frac{|x-m|}{\alpha}\right)^{\beta}\right) 
S\left(\epsilon(x-m)\right)\right] \frac{A}{\text{max}_{x'}}
\label{eq:skew-gen-gauss} 
\end{align}
where $m$ is an $x$-position, $\alpha$ is a scale parameter and $\beta$ is a shape parameter ($\beta < 2$ produces tails that are heavier than Gaussian, $\beta=2$ produces Gaussian tails, and $\beta > 2$ produces lighter than Gaussian tails \cite{nadarajah2005generalized}). The skewness is provided by $S$, which is the sigmoid function:
\begin{align}
S(t) 
&= \frac{1}{1+\exp^{-t}}
\end{align}
applied to $t = \epsilon(x-m)$ with $\epsilon$ a random value $\in [0,1]$. The multiplier $\frac{A}{\text{max}_{x'}}$ controls the peak of the curve, with $\text{max}_{x'}$ the maximum value returned by the weighting function. One of these sources was overlaid with zero-mean, fixed-variance Gaussian noise (with the same variance as background pixels); the other with zero-mean Gaussian noise with variance that increases proportionally with the height of the generated source.  Examples of curves created by Equation \ref{eq:skew-gen-gauss} are shown in Figure \ref{fig:skew-gen-gauss}.

This skewed generalised Gaussian function (Equation \ref{eq:skew-gen-gauss}) was chosen as well as the Gaussian function (Equation \ref{eq:1d-gaussian-fn}) to generate sources as the soft-bordered test region used for evaluation of the DM-Score is the Gaussian function (Equation \ref{eq:region-weight-in-1d}). It is important therefore that all of the sources are not generated using the same function that generates the test region, as this would likely artificially inflate the success of the Dirichlet-multinomial score.  

Some examples of the simulated data are shown in Figure \ref{fig:1d-data-egs}. 

\begin{figure}
\centering
\makebox[\textwidth][c]{\includegraphics[width=1.2\textwidth]{IMAGES/skewed_gen_gaussian_curves.png}}
\caption[Skewed generalised Gaussian curves]{\textbf{Skewed generalised Gaussian curves.} Examples of curves generated by the skewed generalised Gaussian formula in Equation \ref{eq:skew-gen-gauss}. The parameters are: $m \in [0,100]$, $\alpha \in [2,10]$, $\beta \in [0.5,5]$ and $\frac{A}{\text{max}_{x'}} \in [0.5,5]$.}
\label{fig:skew-gen-gauss}
\end{figure}

\begin{figure}
\centering
\makebox[\textwidth][c]{\includegraphics[width=1.2\textwidth]{IMAGES/1d-data-egs.png}}
\caption[Simulated one dimensional data]{\textbf{Simulated one dimensional data.} The data (sources plus Gaussian noise) are shown as black dots with the underlying sources shown as coloured curves. The blue curve is generated by the Gaussian formula (Equation \ref{eq:1d-gaussian-fn}), while the red and green curves are generated by the skewed generalised Gaussian formula (Equation \ref{eq:skew-gen-gauss}). The parameters for the Gaussian curve are: $m \in [0,500]$, $\sigma \in [6,14]$, $A \in [0.5,5]$; and for the skewed generalised Gaussian: $m \in [0,500]$, $\alpha \in [6,14]$, $\beta \in [0.5,5]$ and $\frac{A}{\text{max}_{x'}} \in [0.5,5]$.}
\label{fig:1d-data-egs}
\end{figure}

\subsubsection{Data: two dimensional}
In the case of two dimensional data, simulated data were used for exploratory work, and real data were used to test the methods described in this chapter.

Real data comprised $500 \times 500$ pixel windows of two large astronomical images \cite{norris2006deep}. Each window was treated as a whole image for purposes of evaluation of the DM-Score; windows had an average of $35.9$ sources each (see Table \ref{table:2d-info} and Figure \ref{fig:real-data-2d}). 

``Ground truth" sources and their parameters (central position and coordinates describing a bounding box around each source) were identified using the source-finding package BLOBCAT \cite{hales2012blobcat} with manual postprocessing by an astronomer. Note that the noisy borders of the images were excluded from source detection in construction of the ground truth catalogue \footnote{The area of the two images for source extraction was deﬁned by: rms noise $\le 100 \mu$ Jy beam$^{−1}$; bandwidth smearing $ \ge 80\%$; and mosaicked primary beam response $\ge 40\%$. The defined area covers $3.566$ square degrees of the CDFS image $2.697$ square degrees of the ELAIS image \cite{banfield2013australia}.}.

To obtain the set of windows used for evaluation, $50$ windows were selected at random from the images ($25$ each). Windows were discarded from the evaluation set if they were outside the area used in construction of the ground truth catalogue. This yielded $25$ images for evaluation of the DM-Score ($13$ from ELAIS and $12$ from CDFS).

Note that for the construction of the ground truth catalogue, BLOBCAT was restricted to finding sources at least $4 \sigma$ above rms noise; and the final catalogue was restricted to sources at least $5 \sigma$ above rms noise. This is a key point --- some of the most scientifically important objects in astronomy are those that are dim, with intensities in the range of background noise \cite{norris2011emu}. Current source detection methods restrict search such that dim sources cannot be found. This is due to the nature of the pixel-intensity based thresholding methods that make up the vast majority of current search detection algorithms. If the search is not restricted in this way, the methods will identify far too many background regions as ``sources", and the output will be unusable. The DM-Score does not restrict search in this way, and so can be expected to be more effective at finding dim objects.

\begin{table}
\centering
\caption[Astronomical images used for evaluation of the DM-Score]{Astronomical images used for evaluation}
\begin{tabular}{l c c c c}
\hline
  & ELAIS\protect\footnotemark\cite{norris2006deep}   & CDFS\protect\footnotemark \cite{norris2006deep} \\\hline
Total number ``ground truth" sources in image & 2067         & 3079        \\
Number of sub-windows used                    & 13           & 12          \\
Mean (std dev) sources per window             & 34.7 (11.7)  & 37.2 (8.7)  \\
Min, max number of sources per window         & 16, 53       & 20, 49      \\\hline
\end{tabular}
\label{table:2d-info}
\end{table}
\addtocounter{footnote}{-1}
\footnotetext{Australia Telescope Large Area Survey European Large Area ISO Survey S1} 
\addtocounter{footnote}{1}
\footnotetext{Australia Telescope Large Area Survey Chandra Deep Field-South.}

\begin{figure}
\centering
\makebox[\textwidth][c]{\includegraphics[width=1.0\textwidth]{IMAGES/test.png}}
\caption[Astronomical images used for evaluation of the DM-Score]{\textbf{Examples of astronomical data used for evaluation of the DM-Score.} The images shown are $500 \times 500$ windows from (top) CDFS and (bottom) ELAIS \cite{norris2006deep}. Note that all images are contrast adjusted to show sources.}
\label{fig:real-data-2d}
\end{figure}

Simulated data were created by generating three ``sources" and then overlaying the sources with Gaussian noise\footnote{This is typical of how simulated data were created for evaluation of Bayesian source detection methods, for examples, see: \cite{carvalho2009fast,feroz2008multimodal,guglielmetti2009background,hobson2003bayesian,savage2007bayesian}, each of which simulated sources using the Gaussian formula and overlaid the sources with uncorrelated Gaussian noise.} (zero-mean and, fixed-variance with the same variance of background pixels for one source, variance that increases proportionally with the height of the source for another source, and such that faint sources have lower than average variance for the third source). The sources were generated using the Gaussian ellipse function (with center coordinates $m_x$ and $m_y$, approximate half-widths in orthogonal direction $\sigma_x$ and $\sigma_y$, and rotation parameter $\phi$, and $A$ controlling the height of the peak):
\begin{align}
A\exp\left(- \;\left(a(x-m_x)^2+2b(x-m_x)(y-m_y)+c(y-m_y))^2 \right) \right)\label{eq:2d-testregion}
\end{align}
with:
\begin{align}
a &= \frac{\cos^2(\phi)}{2\sigma_x^2} + \frac{\sin^2(\phi)}{2\sigma_y^2}  \\
b &= \frac{-\sin(2\phi)}{4\sigma_x^2} + \frac{\sin(2\phi)}{4\sigma_y^2}  \\
c &= \frac{\sin^2(\phi)}{2\sigma_x^2} + \frac{\cos^2(\phi)}{2\sigma_y^2} 
\end{align}

Some examples of the simulated data are shown in Figure \ref{fig:sim-ims-dm}.

Performance of the DM-Score on simulated two dimensional data is given in Table \ref{table:2d-sim}, however these results should be read with caution: the sources in the simulated data were generated by a Gaussian ellipse function --- the same function used to generate test regions in an image --- and this may cause the success of the Dirichlet-multinomial Score to be artificially inflated. It is worth noting, however, that authors of other Bayesian source detection methods have used a two dimensional Gaussian to both generate simulated data and as a model for sources in their detection algorithms; for examples, see: \cite{feroz2008multimodal,hobson2003bayesian,savage2007bayesian}.

\begin{figure}
\centering
\includegraphics[width=1.0\textwidth]{IMAGES/sim-ims.png}
\caption[Simulated astronomical images]{\textbf{Simulated astronomical images.} Two images with three simulated sources each are shown at left. The images overlaid with noise are shown at right.}
\label{fig:sim-ims-dm}
\end{figure}

\subsubsection{A note comparing simulated data with real data for evaluation}

Using simulated data for evaluation means that ``ground truth" is known exactly: that is, the parameters of sources in the image are precisely known because they are generated; they do not need to be manually labelled by an astronomer (a time-consuming task), or found by an existing source detection package, or some combination of both methods. This allows precise evaluation of results. However, simulated data do not perfectly mimic the statistical properties of real (astronomical) data\footnote{Simulated data that do emulate the properties of real data well were sought but not available in time for inclusion in this thesis.}. 

On the other hand, labelled data may be incorrectly labelled. In particular, dim sources are often missed by existing source detection packages. If labelled data is missing such sources which are found by the source detection method being evaluated, the detection of these scientifically important sources will be designated as false detections.

In this thesis, early exploration work was done on both simulated and real data. Final evaluation of the DM-Score on one dimensional data was done using simulated data, and on two dimensional data was done on both simulated data and real data labelled by the BLOBCAT source detection package with manual postprocessing.

\subsubsection{Test region}
For one dimensional data, both ``hard" (Equation \ref{eq:hard-borders-wgt}) and ``soft" (Equation \ref{eq:region-weight-in-1d}) test regions were used in early exploration (see Figure \ref{fig:hard-to-soft}). A soft test region was used for evaluation.

For two dimensional data, a Gaussian elliptical test region was used for both early exploration and evaluation; its weighting function $W_{x,y}^{(\theta)}$ is given in Equation \ref{eq:region-weight-in-2d-simpl}.

\subsubsection{Binning strategies}
Equal occupancy and equal width bin border strategies with $K=10$ (Chapter \ref{C:BIN}, Section \ref{sec:binning-strategies}) were used, and the Dirichlet-border ``softening" of both types of bin borders (Chapter \ref{C:BIN}, Section \ref{sec:dirichlet-borders}) was also used with both strategies. Dirichlet bin border strategies used a symmetric $\boldsymbol{\alpha}$-vector with $\alpha_i = 10 \; \forall i \in K$, to make $50$ sets of bins.

\subsection{Derivation of $\boldsymbol{\alpha}^S$ and $\boldsymbol{\alpha}^B$}\label{sec:alphas}
The Dirichlet-multinomial score (Equation \ref{eq:score2}) compares the binned counts in a region with theoretical ``background" and ``source" distributions. More precisely, it compares the $\boldsymbol{\alpha}$-vectors of Dirichlet distributions from which multinomial distributions over bins for ``background" and ``source" distributions are drawn.

The $\boldsymbol{\alpha}$-vectors may be derived from a process such as latent Dirichlet allocation (Chapter \ref{C:LDA}), where the distribution over bins in ``source" and ``background" topics may be used for the respective $\boldsymbol{\alpha}$-vectors. This approach is explored\footnote{Note that topic distributions inferred by LDA are multinomial distributions, not Dirichlet distributions; however they may be used to approximate each other \cite{johnson1960approximation,johnson1997discrete}; this is discussed more in Chapter \ref{C:2D-LDA}.} in Chapter \ref{C:2D-LDA}.

Alternatively, the data itself may be treated as pseudocounts, and be used directly as $\boldsymbol{\alpha}$-vectors. 

As an example of using the data directly as $\boldsymbol{\alpha}$-vectors, a human expert (such as an astronomer) might manually select a source-free area of ``typical background" within an astronomical image. Binning the pixels in this region into bins defined on the whole image would yield an $\boldsymbol{\alpha}^B$-vector that could be used in the DM-Score in Equation \ref{eq:score2}. Such manual selection is however costly and impractical, and may be biased by the idiosyncrasies of the human perceptual system.

Obviating the need for manual selection of a ``typically background" region, the \emph{whole image} may be used as the $\boldsymbol{\alpha}^B$-vector. That is, the whole image is binned according to a particular binning strategy, and the binned-counts are used as the $\boldsymbol{\alpha}^B$-vector. In terms of a generative model for background, distributions over bins for background regions are drawn from a Dirichlet with this $\boldsymbol{\alpha}^B$-vector. This is particularly appropriate for astronomical images in which background pixels far outnumber source pixels --- in any particular background region, one would expect relatively few source pixels. This ``whole image as background" approach is taken in this chapter.

The $\boldsymbol{\alpha}^S$-vector may similarly be derived from a process such as latent Dirichlet allocation or manually defined by an astronomer. 

A source model with the symmetric $\boldsymbol{\alpha}$-vector with $\alpha_i = \alpha_j = 1 \; \forall i,j \in 1,...,K$ does not incorporate any knowledge about what a source distribution might be; all multinomial distributions over $K$ bins are equally likely to be drawn from the Dirichlet distribution with this $\boldsymbol{\alpha}$-parameter \cite{frigyik2010introduction}. In this chapter, $\boldsymbol{\alpha^S}$ was set to this $\boldsymbol{\alpha}$-vector.

Given these parameterisations for $\boldsymbol{\alpha}^B$ and $\boldsymbol{\alpha}^S$, background regions are expected to have a similar distribution over bins as the whole image does; while a source region may have any distribution over $K$ bins. A high DM-Score using Equation \ref{eq:score2} means that the counts \textbf{n} in a region are highly dissimilar to those expected under multinomial distributions drawn from a Dirichlet distribution having parameter vector $\boldsymbol{\alpha}^B$. So, for example, a region in which there is a higher proportion of bright pixels than is typical in the image would receive a high DM-Score. More generally, regions in the image with \textit{any} ``unusual" distributions across bins will correspond to peaks in score.

Because any unusual distribution conforms better to the source model than the background model using this parametrisation, a region with more dark pixels than is typical would get a higher DM-Score than a region that conforms perfectly to the background model. Similarly, regions of lower than usual variance in an image would conform better to the ``agnostic" source model than the whole-image-as-background model (for examples of simulated low variance sources, see Figures \ref{fig:1d-score-egs2} and \ref{fig:hard-to-soft}).

This broad definition of non-background like regions in an image allows a great deal of flexibility in the use of the DM-Score to find different types of features in astronomical images.

However in the context of identifying sources (which are generally brighter than background pixels), such dark or low variance regions are, although possibly worthy of attention, unlikely to be real sources. The $\boldsymbol{\alpha}^S$-vector could therefore be adapted to have high values in the region of bright pixels, for example $a_i > 1$ where $i > \epsilon$, and $\epsilon$ is some brightness threshold. Similarly, the $\boldsymbol{\alpha}^S$-vector could otherwise be set to identify features of an image with particular known characteristics. This approach was not taken in this chapter (however see Chapter \ref{C:2D-LDA} in which the $\boldsymbol{\alpha}^S$-vector is set according to the source model derived by LDA).

\subsection{Dirichlet-multinomial Score}\label{sec:meth-score}

A heuristic value for the prior for the ratio of source to background pixels in the image of $0.05/0.95$ was used in place of the second term in Equation \ref{eq:score2}. This reflects the prior belief that radio astronomy images are dominated by background.

\subsubsection{Exhaustive calculation of the score for one dimensional data}

For illustrative purposes, the DM-Score and its gradient was exhaustively calculated over a range of values for parameters $\theta$ on a number of simulated one dimensional images.

\begin{figure}
\centering
\makebox[\textwidth][c]{\includegraphics[width=1.2\textwidth]{IMAGES/1d-score-egs1.png}}
\caption[Exhaustive calculation of the DM-Score and its gradient (1)]{\textbf{Exhaustive calculation of the DM-Score and its gradient.} Three sources have parameter $m = (38, 219, 389)$. The top plot uses Dirichlet equal width bins; the bottom Dirichlet equal occupancy. Details are in text in Section \ref{sec:meth-score}.}
\label{fig:1d-score-egs1}
\end{figure}

\begin{figure}
\centering
\makebox[\textwidth][c]{\includegraphics[width=1.2\textwidth]{IMAGES/1d-score-egs2.png}}
\caption[Exhaustive calculation of the DM-Score and its gradient (2)]{\textbf{Exhaustive calculation of the DM-Score and its gradient.} Three sources have parameter $m = (165, 410, 446)$. The top plot uses equal width bins, the bottom Dirichlet equal occupancy. Details are in text in Section \ref{sec:meth-score}. Note that the source at $m = 446$ has lower variance than is typical of the image.}
\label{fig:1d-score-egs2}
\end{figure}

\begin{figure}
\centering
\makebox[\textwidth][c]{\includegraphics[width=1.2\textwidth]{IMAGES/1d-score-egs3.png}}
\caption[Exhaustive calculation of the DM-Score and its gradient (3)]{\textbf{Exhaustive calculation of the DM-Score and its gradient.} Three sources have parameter $m = (145, 275, 354)$. The top plot uses Dirichlet equal width bins, the bottom equal occupancy. Details are in text in Section \ref{sec:meth-score}.}
\label{fig:1d-score-egs3}
\end{figure}

Figures \ref{fig:1d-score-egs1} to \ref{fig:1d-score-egs3} show the DM-Score and its gradient over $m \in [0..500]$ and $\sigma \in [0..250]$. Each of the six plots has three subplots: a plot of the data (black dots) with blue lines at the location of bin borders; a plot of the binned data (blue square dots); and a plot of the score-space, with parameter $m$ on the $x$-axis and $\sigma$ on the $y$-axis. Each point in the space is coloured along a continuum indicating whether background or source is favoured. Gradient lines (black) are superimposed.  

Note that in each of the three figures, in general, high scores correspond to the location of sources, while the rest of the image has scores that tend strongly towards the background model. Gradient lines converge at the peaks of the regions of source scores.

Unsurprisingly, bright and large sources appear to be the easiest to find: the peak at $m = 38$ in Figure \ref{fig:1d-score-egs1}, at $m = 410$ in Figure \ref{fig:1d-score-egs2}, and at $m = 275$ in Figure \ref{fig:1d-score-egs3} correspond with the darkest blue (most source-like) regions in the score space. Note however that the dim, low variance source at $m = 466$ in Figure \ref{fig:1d-score-egs2} is also well found.

\subsubsection{Background-compensation correction to the Score}

The parametrisation of $\boldsymbol{\alpha}^B$ and $\boldsymbol{\alpha}^S$ described in Section \ref{sec:alphas} biases the Dirichlet-multinomial Score towards higher values for smaller regions. 

This is due to the fact that the whole (binned) image is taken as pseudo-counts for the background model, and the source model is constructed to give all multinomial distributions over $K$ bins equal probability. When the number of pixels $N$ in a region \textbf{n} gets small, the binned counts in that region are more likely to be dissimilar to the binned counts in the whole image by chance alone. In fact, where the number of pixels $N$ in a region \textbf{n} is smaller than the number of bins $K$, there is guaranteed to be at least one empty bin (a bin with a count of $0$); in the extreme, a region of one pixel will have one bin occupied and $K-1$ bins empty. Such small regions look dissimilar to the background model. As all multinomial distributions are equally favoured by the source model, these small regions are favoured by the source model. Therefore the score in such regions is artificially inflated.

This biasing of the score towards small regions can be seen in Figure \ref{fig:background-correction}.

\begin{figure}
\centering
\makebox[\textwidth][c]{\includegraphics[width=1.4\textwidth]{IMAGES/background-correction.png}}
\caption[Background compensation correction to the DM-Score]{\textbf{Background compensation correction to the DM-Score.} Both plots show an exhaustive calculation of the score and its gradient over parameters $\theta = (m,\sigma)$ on simulated one dimensional data. The score is shown as a red to blue colour gradient, the gradient of the score as black lines. All parameters are the same in both plots. The upper plot shows the uncorrected score, while the lower shows the corrected score using Equation \ref{eq:corrected-score}. Numerous spurious peaks in the DM-Score into which gradient lines converge can be seen in the plot of the uncorrected score as peaks at low $y$-values (that is, small test regions). In the corrected version these have disappeared.}
\label{fig:background-correction}
\end{figure}

To compensate for this biasing, a background correction can be added to the DM-Score:
\begin{align}
\text{Score'}
&= \text{Score} - \text{Score}^{B} 
\label{eq:corrected-score}
\end{align}

Where $\text{Score}^B$ is the Dirichlet-multinomial score on the vector $\mathbf{n}^B$, defined to be:
\begin{align}
\mathbf{n}^B
&=\frac{\boldsymbol{\alpha}^B}{A^B} N
\end{align}

That is, the vector $\mathbf{n}^B$ is constructed to have proportionally the same counts in bins as $\boldsymbol{\alpha}^B$, scaled by the size of the region. This therefore compensates for the effect of smaller windows having an artificially inflated DM-Score by virtue of size alone.

The gradient of this corrected score is readily calculated:
\begin{align}
\text{Gradient'}
&= \text{Gradient} - \text{Gradient}^{B} 
\end{align}
as $\mathbf{n}^B$ simply replaces $\mathbf{n}$ in the score and gradient calculations, both of which are binned counts in a region.

This background compensation to the DM-Score was used for one dimensional data only; early exploration indicated that is was not needed for two dimensional data. It is possible that this is due to the fact that ``small regions" in one dimensional space are more likely to have fewer pixels than such regions in two dimensional space. A thorough exploration is warranted but was not done for this thesis.


\subsection{Gradient ascent}\label{sec:grad-asc-1d}
For one dimensional data, the gradient of the DM-Score was calculated using the Gaussian function parametrisation of the window function $W^{(\theta)}$ (Equation \ref{eq:region-weight-in-1d}) used to define a test region. For the derivative with respect to $m$ and $\sigma$ for this parametrisation, see Equations \ref{eq:1dgrad-wrt-position} and \ref{eq:1dgrad-wrt-sigma}.

For illustrative purposes, the gradient was exhaustively calculated over a range of values for parameters $\theta = (m,\sigma)$ on a number of images, real and generated; see Figures \ref{fig:1d-score-egs1} to \ref{fig:1d-score-egs3}.

Similarly, for two dimensional data, the gradient of the score was calculated using the Gaussian function parametrisation of the window function $W^{(\theta)}$ (Equation \ref{eq:region-weight-in-2d-simpl}) for a test region. The gradient with respect to $\theta$ for this parametrisation can be found in Section \ref{sec:grad-score} of Chapter \ref{C:1D}.

The \texttt{fmin\_tnc} function from the Python package \texttt{scipy.optimize} \cite{scipy} was used to implement gradient ascent. This function uses a Newton Conjugate-Gradient algorithm, and allows each parameter to have bounds: user-defined minimum and maximum values that a parameter can take \cite{scipy,nash1984newton,nocedal2006numerical}. For example, the parameter $m_x$ would have its minimum value $=0$ and its maximum value $=X$ where there are $X$ pixels in a one dimensional image.

In the case of one dimensional data, one ``round" of source finding consisted of 50 trials of gradient ascent, each with random initial values for parameters $\theta$.

For two dimensional data one ``round" of source finding consisted of 50 trials of gradient ascent for simulated data, and just one trial of gradient ascent for real data (to speed up execution time). For both real and simulated two dimensional data, initial values for parameters $m_x, m_y$ were set to the coordinates of the brightest pixel in the image\footnote{In the case where there was more than one pixel with the maximum intensity value in the image, one of these pixels was chosen at random to set the initial values for $m_x, m_y$.}, with random initial values for $\sigma_x$, $\sigma_y$, and $\phi$. Initialising search at the brightest point saved computational time and made use of the domain knowledge that sources are brighter than background.

The peak with the highest score in each round was recorded as a found source. That source was then removed from the data by replacing the pixels of the found source with NaNs. The pixels of the found source were defined by $m \pm 1.5 \sigma$ for one dimensional data, and similarly, the pixels in the ellipse defined by the found source's parameters $(m_x, m_y, 1.5\sigma_x, 1.5\sigma_y, \phi)$ for two dimensional data.

After each source removal, the histogram bin borders and the $\boldsymbol{\alpha}^B$-vector were re-calculated on the remaining data. 

For simulated data, three rounds were performed per image.

For two dimensional real data, rounds of gradient ascent continued until the top-scoring source of a round had a score that indicated it was more likely to be background than source, or after $53$ rounds (the maximum number of sources in any window, see Table \ref{table:2d-info}), whichever came first.

\subsection{Evaluation methods}
Because the test regions are continuous in the image, for the purposes of evaluation the region of a found source is restricted to $m \pm 2\sigma$ for one dimensional data, and the ellipse defined by the parameters $\theta = (m_x, m_y, \\2\sigma_x, 2\sigma_y, \phi)$ for two dimensional data. This is equal to $95$ per cent of the area under the curve generated by the Gaussian function \cite{wasserman2004all}.

In the case of real data, ``true sources" were those identified by the source-finding package BLOBCAT \cite{hales2012blobcat} with manual postprocessing by an astronomer. These sources have position parameters including the $x,y$ coordinates of a source's centre, and minimum and maximum pixel coordinates in both directions: $min_x, max_x, min_y, max_y$. These coordinates can be used to describe a ``bounding box" around the source. Note that the sources in this ground truth catalogue are restricted to those at least $5 \sigma$ above rms noise --- because the DM-Score has no such restriction this means that any sources below $5 \sigma$ above rms noise found by the DM-Score will be designated false positives when comparing them against the ground truth catalogue.

In the case of simulated one dimensional data, a ``true source" was defined as  $m \pm 2\sigma$ for Gaussian sources, and $[x_a,x_b]$ for skewed generalised Gaussian sources where $x_a$ and $x_b$ are the minimum and maximum pixel coordinates for the region where each pixel is $\ge 0.05 \times x_{max}$ (and $x_{max}$ is the maximum intensity value of the curve).

Precision and recall were calculated in order to evaluate the performance of the Dirichlet-multinomial score. Precision is the proportion of true sources of all found sources (that is, all found sources that are really sources):
\begin{align}
\text{precision} &= \frac{\textbf{tp}}{\textbf{tp}+\textbf{fp}}
\end{align}
and recall is the proportion of found sources of all true sources in the image (all true sources that are found):
\begin{align}
\text{recall} &= \frac{\textbf{tp}}{\textbf{tp}+\textbf{fn}}
\end{align}
where $\textbf{tp} =$ ``true positive", $\textbf{fp} =$  ``false positive", and $\textbf{fn} =$ ``false negative"\footnote{Precision and recall are sometimes called ``completeness" and ``reliability" in the astronomical source detection literature \cite{hancock2012compact}.} \cite{olson2008advanced}.

A true positive is defined where the location of at least $50$ per cent of a found source's pixels overlap with at least $50$ per cent of a real source's pixels. A false positive is a found source that does not meet these criteria, a false negative is a true source that does not meet these criteria. In the case of simulated data, because there are three sources per image, and three rounds of gradient ascent producing three found sources per image, \textbf{fp} $=$ \textbf{fn} and so precision $=$ recall.

For simulated one dimensional and two dimensional data, precision and recall was additionally calculated over a range of proportions from $prop=0.05$ to $prop=0.95$ where a true positive is defined where the at least the given proportion of a found source's pixels overlap with at least that same proportion of a real source's pixels, in order to compare the performance of different binning strategies at different thresholds. These results are shown in Figures \ref{fig:1d-sim-thresholds} and \ref{fig:1d-sim-thresholds}.

\section{Results and discussion}\label{sec:results}

\subsection{One dimensional data}

\begin{table}
\centering
\caption[Performance of the DM-Score (simulated 1D)]{Performance of the DM-Score on simulated one dimensional data}
\begin{tabular}{l c c }
\hline
Binning method  & Precision & Recall \\\hline
Equal width & 0.84 & 0.84  \\
Dirichlet equal width & 0.77 & 0.77 \\
Equal occupancy & 0.68 & 0.68 \\
Dirichlet equal occupancy & 0.71 & 0.71 \\\hline
\end{tabular}
\label{table:1d-sim}
\end{table}

Early exploration on one dimensional data suggested soft-bordered test regions improved the DM-Score as compared to hard-bordered test regions. Figure \ref{fig:hard-to-soft} shows representative plots illustrating an improvement to the DM-Score on simulated one dimensional data using soft-bordered, as compared to hard-bordered test regions. For this reason, soft bordered test regions were used for the remainder of the analysis of the DM-Score.

Figure \ref{fig:1d-comp-binning} shows an exhaustive calculation of the score for a one dimensional ``slice" of an astronomical image, as well as the top scoring peaks of five rounds of gradient ascent, for each of the four different binning strategies used in this chapter. 

Table \ref{table:1d-sim} shows the performance of the DM-Score on $50$ simulated one dimensional images (such as those shown in Figure \ref{fig:1d-data-egs}), each of which contains three sources. Note that the rates for precision and recall are identical within each binning method, due to the fact that three rounds of gradient ascent were performed for each image. Therefore the number of false positives $=$ the number of false negatives $=$ ($1-$ the number of true positives). Precision and recall are moderate to high for each of the binning strategies. It is worth noting that the Dirichlet softening of bin borders improved results only for the equal occupancy strategy, and actually worsened performance in the case of equal width bin borders. An investigation into why this might be would be worth pursuing but was not done for this thesis.

\begin{figure}
\centering
\makebox[\textwidth][c]{\includegraphics[width=1.4\textwidth]{IMAGES/hard-to-soft-borders1.png}}
\caption[Hard-bordered versus soft-bordered test regions]{\textbf{Hard and soft borders.} Results of the DM-Score with hard-bordered (Equation \ref{eq:hard-borders-wgt}; top) versus soft-bordered (Equation \ref{eq:region-weight-in-1d}; bottom) test regions on one dimensional simulated data. The plots at left have three subplots; from top to bottom: the data (black dots) with bin borders superimposed (blue lines; with histogram binning at right), the binned data (blue dots), and a plot of the score over a range of values for $\theta = (m,\sigma)$. The plots at right show the data (black dots) with sources shown as blue curves (with $m \pm 1 \sigma$ shown as green dots). The red lines are at $1$ where the score $> 0$, and $0$ elsewhere. Note that number of false positives drastically reduces when using soft-bordered test regions. Note also the low variance source (far right of each plot), found by the DM-Score.}
\label{fig:hard-to-soft}
\end{figure}

\begin{figure}
\centering
\makebox[\textwidth][c]{\includegraphics[width=1.45\textwidth]{IMAGES/1d-comp-binning.png}}
\caption[Peaks found in a one dimensional ``slice" of an image]{\textbf{The DM-Score on a one dimensional ``slice" of an astronomical image} (ATLSB survey region A at $50"$ resolution \cite{saripalli2012atlbs,subrahmanyan2010atlbs}; see Figure \ref{fig:1d-real}). Results using equal occupancy (top left), equal width (top right), Dirichlet equal occupancy (bottom left), and Dirichlet equal width (bottom right) histogram binning strategies. The main body of each plot shows an exhaustive calculation of the score over parameters $\theta = (m, \sigma)$ with $m \in [0 .. X]$ and $\sigma \in [0 .. \frac{X}{2}]$. The top scoring maxima from five rounds of gradient ascent with 50 trials each are shown as black \texttt{\textbf{x}} marks. In the top two plots, the top sub-plot shows the data in black with blue bin borders superimposed; the next sub-plot down is the binned data (blue dots). Note that for this example peaks in gradient best correspond to the actual peaks in data in the case of the Dirichlet equal width binning strategy.}
\label{fig:1d-comp-binning}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=1.0\textwidth]{IMAGES/1d-sim-thresholds.png}
\caption[The DM-Score on at different thresholds (1D)]{\textbf{The performance of the DM-Score at different thresholds} (one dimensional data, 50 simulated images, three sources each). Thresholds are defined as the proportion of a true source and an estimated source that must overlap to be defined as a true positive. For example at a threshold of $0.5$, a true positive is defined where the location of at least $50$ per cent of a found source's pixels overlap with at least $50$ per cent of a real source's pixels. Note that the precision exceeds $1.0$ for some binning strategies at thresholds $\le 0.3$, as each estimated source may meet the definition of true positive for more than one true source at such a low threshold.}
\label{fig:1d-sim-thresholds}
\end{figure}

Precision and recall was also calculated over a range of proportions from $prop=0.05$ to $prop=0.95$ (defining the proportion of pixels that must overlap between a true source and found source to be considered a true positive). These results are shown in Figure \ref{fig:1d-sim-thresholds}. The performance of each binning strategy drops off as the proportion increases. The relative performance of each of the four binning strategies remain relatively even across all thresholds, except that at very low thresholds the Dirichlet equal width binning strategy outperforms the equal width binning strategy.

\subsection{Two dimensional data}

Early exploration of the DM-Score on two dimensional data used simulated images (such as those shown in Figure \ref{fig:sim-ims-dm}). 

Figure \ref{fig:eqdir-binned-score} illustrates an exhaustive calculation of the DM-Score on two dimensional simulated data over $x$ and $y$ positions $\theta = (m_x, m_y)$ with other parameters kept constant. The positions of the original sources are recovered almost perfectly, despite the fact that they are obscured with noise.

Precision and recall were calculated for the $50$ simulated images (with three sources per image), with results\footnote{Note that as for the simulated one dimensional data, the rates for precision and recall are identical within each binning method, as three rounds of gradient ascent were performed for each image; therefore the number of false positives $=$ the number of false negatives $=$ ($1-$ the number of true positives).} shown in Table \ref{table:2d-sim}. Scores were high for three of the four binning strategies, but perplexingly low for the Dirichlet equal width binning strategy. Figure \ref{fig:2d-sim-thresholds} shows the performance of the four binning strategies over a range of thresholds defining a true positive. This reveals that the poor performance of the Dirichlet equal width strategy held only at thresholds $\ge 0.4$; under this threshold, the Dirichlet equal width strategy performed in the range of (and often better than) the other strategies. 

A closer inspection of the results shows that this may be explained by the fact that Dirichlet equal width binning strategy resulted in found sources that are in most cases much smaller than the actual sources, but located in the correct position (see Figure \ref{fig:2d-sim-dirwid}) for examples. This may be due to the fact that equal width binning places the brightest pixels alone in bins, when these bright pixels are outliers and the vast majority of pixels lie in a small dim intensity range (as with radio astronomy images). The Dirichlet softening of equal width bin borders may shift bright pixels that are close to bin borders pixels down to dimmer bins. It is possible that the background compensation correction to the score, described in Section \ref{sec:meth-score} may address this issue (although this correction was not applied to two dimensional data for this thesis). 

\begin{figure}
\centering
\includegraphics[width=1.0\textwidth]{IMAGES/eqdir-binned-score.png}
\caption[Exhaustive calculation of the DM-Score (2D)]{\textbf{An exhaustive calculation of the DM-Score} on two dimensional simulated data over $x$ and $y$ positions $\theta = (m_x, m_y)$ with parameters $\sigma_x$,  $\sigma_y$ and $\phi$ kept constant. From left to right: three simulated sources; the image overlaid with Gaussian noise; the noisy image binned with Dirichlet equal occupancy bins; the DM-Score over $(m_x,m_y)$ calculated using these bins, shown using a colour gradient from red (background) to blue (source). Note that all three sources are recovered. The blue peaks in score for two of the three sources in the image at right indicate high scores for these sources, and roughly equal scores despite the bottom source being brighter than the top one. The score for the dim source is relatively lower than that for the other two sources, however it still exceeds a score that would indicate ``background", relative to the true background regions.} 
\label{fig:eqdir-binned-score}
\end{figure}

\begin{table}
\centering
\caption[Performance of the DM-Score (simulated 2D)]{Performance of DM-Score on simulated two dimensional data}
\begin{tabular}{l c c}
\hline
Binning method  & Precision & Recall \\\hline
Equal width & 0.83 & 0.83  \\
Dirichlet equal width & 0.57 & 0.57 \\
Equal occupancy & 0.79 & 0.79 \\
Dirichlet equal occupancy & 0.84 & 0.84 \\\hline
\end{tabular}
\label{table:2d-sim}
\end{table}

\begin{figure}
\centering
\includegraphics[width=1.0\textwidth]{IMAGES/2d-sim-thresholds.png}
\caption[The DM-Score on at different thresholds (2D)]{\textbf{The performance of the DM-Score at different thresholds} (two dimensional data, $50$ simulated images, three sources each). Thresholds are defined as the proportion of a true source and an estimated source that must overlap to be defined as a true positive. For example at a threshold of $0.5$, a true positive is defined where the location of at least $50$ per cent of a found source's pixels overlap with at least $50$ per cent of a real source's pixels.}
\label{fig:2d-sim-thresholds}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=1.0\textwidth]{IMAGES/2d-sim-dirwid.png}
\caption[Gradient ascent on the DM-Score (2D)]{\textbf{Results of gradient ascent on the DM-Score} using Dirichlet equal width bins on simulated two dimensional images (shown without noise for clarity). The found sources are shown as green ellipses with a red cross at the central $x,y$ coordinates of the found source. Note that the found sources are much smaller than the actual sources, which may account for the poor performance of this binning strategy at thresholds over $0.4$, where thresholds are defined as the proportion of a true source and an estimated source that must overlap to be defined as a true positive. }
\label{fig:2d-sim-dirwid}
\end{figure}

The performance of the DM-Score on $25$ windows from two large astronomical images \cite{norris2006deep} is shown in Table \ref{table:2d-real-res}. 

\begin{table}
\centering
\caption[Performance of the DM-Score (real 2D)]{Performance of the DM-Score on real two dimensional data}
\begin{tabular}{l c c}
\hline
Binning method & Precision & Recall \\\hline
Equal width               & 0.51 & 0.74 \\
Dirichlet equal width     & 0.59 & 0.75 \\ 
Equal occupancy           & 0.30 & 0.30 \\
Dirichlet equal occupancy & 0.32 & 0.34 \\\hline
\end{tabular}
\label{table:2d-real-res}
\end{table}

Results obtained using equal occupancy binning (with and without Dirichlet softening of bin borders) are very low, in comparison both to results obtained on simulated data, and equal width results on real data. This may possibly be attributed to the source finding process, in which each round of gradient ascent is initialised at a bright point in the data, and finishes with the removal of the found source and recalculation of the $\boldsymbol{\alpha}^{B}$-vector and bin borders. For radio astronomy data where the vast majority of pixels fall into a low intensity range with a small number of bright outliers, this process lends itself to equal width binning strategies. In such strategies, the brightest pixels will be binned alone; iterative removal of these pixels and recalculation of the bins will reveal the next brightest pixels, and so on. Figure \ref{fig:progbinned} illustrates this point.

With regards to the equal width binning strategies, the precision and recall of the DM-Score on the real two dimensional data is lower than the results on the simulated one dimensional and two dimensional data. Though the rate of recall is good ($0.74$ and $0.75$), precision, in particular, is very low ($< 0.6$) on the full set of sources found. 

Low precision can in part be explained by the fact that the DM-Score found more sources than appear in the ground truth catalogue. While some of these additional found sources are spurious, some do appear to be sources that were missed by BLOBCAT with manual postprocessing. This is not surprising given that the ground truth catalogue only contained sources at least $5 \sigma$ above rms noise, while the DM-Score was not restricted in this way. In fact, even the raw BLOBCAT output (without manual postprocessing) had precision of only $0.69$ when compared to the ground-truth catalogue.

Examples of found sources that were not found by BLOBCAT and are not in the ground truth catalogue can be seen in Figure \ref{fig:comps}.

The Dirichlet bin border softening improved results for both equal width and equal occupancy strategies on this data.

\begin{figure}
\centering
\makebox[\textwidth][c]{\includegraphics[width=1.0\textwidth]{IMAGES/progbinned.png}}
\caption[Iterative source removal and rebinning]{\textbf{Iterative source removal and rebinning.} After each round of gradient ascent, the found source is removed from the data and bin borders and the $\boldsymbol{\alpha}^B$-vector are recalculated on the remaining image. From left to right: the binned view of the initial image (a window from CDFS using Dirichlet equal width bins), the binned image after one, two and three rounds of gradient ascent. Notice that removing sources and rebinning the remaining data reveals sources that were previously hidden in background bins.} 
\label{fig:progbinned}
\end{figure}

\begin{figure}
\centering
\makebox[\textwidth][c]{\includegraphics[width=1.0\textwidth]{IMAGES/comparisons.png}}
\caption[Comparison with the ground truth catalogue]{\textbf{Comparison with the ground truth catalogue.} A section of one of the CDFS test-windows is shown at top left. Top right shows the sources identified by BLOBCAT (raw, unprocessed output). Bottom left shows the sources in the ground-truth catalogue, and bottom right the sources identified by the DM-Score. Note that the DM-Score has identified all the sources in the ground truth catalogue, and in addition, has found part of a low brightness source (radio galaxy tail; pink ring). The DM-Score has also correctly identified two separate sources that the ground truth catalogue identified as one source (blue ring), though one of the DM-Score's width parameters for the upper source is incorrect.} 
\label{fig:comps}
\end{figure}


%results for raw blobcat output:
%elais: prec $= 0.68$; recall $= 0.93$
%cdfs: prec $= 0.71$; recall $= 0.95$

\section{Conclusions and future work}

\subsection{Simulated data}

Precision and recall rates for the DM-Score on both one and two dimensional simulated data were moderate to good, especially given the nature of the simulated data --- care was taken to generate sources that differed from the DM-Score's model for sources. In comparison, the simulated data used by other authors of Bayesian source detection methods generate sources with the same parameters as the model of source used in the detection methods. For example, many authors generate circularly symmetric Gaussian sources of a particular size, and use a circularly symmetric Gaussian of that size as a source model (see: \cite{feroz2008multimodal,hobson2003bayesian,savage2007bayesian}). Using the same parameters for simulated source and the method's source model is likely to artificially inflate the success of the model, and is unjustified in the case of radio astronomy data, where sources can take a great variety of shapes and sizes.

A particular strength of the DM-Score is illustrated in Figures \ref{fig:1d-score-egs2} and \ref{fig:hard-to-soft}: the identification of low variance sources. The ability to set the source model to an $\boldsymbol{\alpha}$-vector that is completely ``agnostic" creates a broad definition of non-background like regions in an image that allows a great deal of flexibility in the use of the DM-Score to find different types of features in astronomical images.

With regards to the background-compensation correction to the score, initial investigation indicates that this correction improves results for one dimensional but not two dimensional data. The reasons for this are not clear and further investigation is warranted.

\subsection{Real data}

The performance of the DM-Score using the Dirichlet equal width binning strategies on $25$ windows from two large astronomical images yielded good recall ($0.75$), and moderate precision ($0.59$).

This moderate precision can in part be attributed to the fact that the ground truth catalogue was restricted to sources at least $5 \sigma$ above rms noise. Though some of the DM-Score's false positives were regions of noise, many were real sources below this threshold (Figure \ref{fig:comps}).

As noted earlier in this chapter, some of the most scientifically important objects in astronomy are dim, with intensities in the range of background noise \cite{norris2011emu}. The nature of pixel-intensity based thresholding algorithms such as BLOBCAT restricts their ability to find such dim sources without also finding such a large number of noise regions that the results are unusable.

The DM-Score does not restrict the objects found on the basis of some threshold above rms noise, and produces raw results containing most real objects, including dim sources not well found by other other algorithms, while returning only a moderate number of false positives in regions of noise.

Though further development of the score is needed, the DM-Score finds sources well and is in many cases better at finding scientifically important dim sources. It is approaching a usable algorithm that does not require the intensive manual parameter tuning of existing algorithms --- the need for source finding software with a minimum of manual tuning is pressing, given the huge volumes of data to be produced by the next generation of radio astronomy telescopes \cite{norris2011emu}.

A significant drawback of the implementation of the DM-Score in this thesis however, is that the gradient ascent process was too slow to be practical (or even possible) on full-sized images. Future work to improve this is needed. One aspect that could be improved to speed up this process is the use of a test region with finite support. The use of a Gaussian distribution for test regions mean that regions extend potentially across the whole image, slowing down the gradient ascent process. This was also an issue for at least one other Bayesian source detection algorithm \cite{feroz2008multimodal} for which investigation into alternative distributions to the Gaussian is ongoing. 

An issue with the process within which the DM-Score is used in this chapter is that the iterative removal of found sources sometimes leaves artefacts around the removed source. This can cause multiple ``found sources" where in fact only one source lies (see Figure \ref{fig:false-positives} for an example). Addressing this issue may reduce the number of false positives caused by multiple found sources on one true source.

\begin{figure}
\centering
\makebox[\textwidth][c]{\includegraphics[width=1.0\textwidth]{IMAGES/false-positives.png}}
\caption[False positives due to multiple peaks on one source]{\textbf{False positives due to multiple peaks on one source.} Iterative removal of sources can leave artefacts around the removed source, which can cause the DM-Score to find more ``sources" than there actually are in an image. The pink circles indicate regions where this has occurred.} 
\label{fig:false-positives}
\end{figure}

\subsection{Binning strategies}

The results of the DM-Score in this chapter are inconclusive with regards to which binning strategy is best, and whether or not the novel method for incorporating uncertainty about bin border locations --- Dirichlet softening --- improves the performance of the equal width and equal occupancy binning strategies.

While the width-based strategies were superior for simulated one dimensional and real two dimensional data (improving results more than two-fold for the latter), the occupancy-based strategies yielded better results in the case of simulated two dimensional data. A fuller comparison of binning strategies is warranted.

In the case of simulated data, the Dirichlet softening of bin borders improved performance for equal occupancy binning but deteriorated performance for equal width binning strategies (however, note the impact of changing the threshold at which true positives are defined; Figure \ref{fig:2d-sim-thresholds}). For real data, Dirichlet softening improved both equal width and equal occupancy strategies.

The Dirichlet softening of bin borders in this chapter used a symmetric $\boldsymbol{\alpha}$-vector with $\alpha_i = 10$. The Dirichlet with this $\boldsymbol{\alpha}$-vector produces more uniform distributions over $K$ bins than one with values $< 10$, for example. Lower $\alpha$ values would introduce more variation into the location of bin borders. The effects of different $\boldsymbol{\alpha}$-vectors in softening bin borders is worth investigating further.

\subsection{Potential extensions to the DM-Score}

The second term in the DM-Score (Equation \ref{eq:score2}) weights the likelihood of a region being source or background by the relative proportion of each in the image. This term was set heuristically in this chapter, to reflect the prior belief that astronomical images are dominated by background pixels. However, the DM-Score could be extended to incorporate a Dirichlet hyperparameter over the source and background mixing proportions in an image or regions within that image. The mixing proportions could be modelled as a multinomial distribution, similar to the mixing proportions over topics in LDA (Chapter \ref{C:LDA}).

In this chapter, the $\boldsymbol{\alpha}^S$-vector of the DM-Score was set to the symmetric $\boldsymbol{\alpha}$-vector with $\alpha_i = 1$, in order to give equal likelihood to all multinomial distributions over $K$ for source regions (so that source regions were defined as ``non-background"). It would be useful to explore ways of setting the $\boldsymbol{\alpha}^S$-vector such that particular distributions are favoured over others. Chapter \ref{C:2D-LDA} explores one such setting of the $\boldsymbol{\alpha}^S$-vector, by using the source and topic distributions output by LDA as $\boldsymbol{\alpha}$-vectors in the DM-Score.


