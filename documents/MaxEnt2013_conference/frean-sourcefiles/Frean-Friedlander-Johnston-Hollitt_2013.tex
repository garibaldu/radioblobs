%% ****** Start of file aiptemplate.tex ****** %
%%
%%   This file is part of the files in the distribution of AIP substyles for REVTeX4.
%%   Version 4.1 of 9 October 2009.
%%
%
% This is a template for producing documents for use with 
% the REVTEX 4.1 document class and the AIP substyles.
% 
% Copy this file to another name and then work on that file.
% That way, you always have this original template file to use.

\input{aipcheck}

\documentclass[
    ,final            % use final for the camera ready runs
%%  ,draft            % use draft while you are working on the paper
%%  ,numberedheadings % uncomment this option for numbered sections
%%  ,                 % add further options here if necessary
  ]
  {aipproc}

\layoutstyle{8x11double}

\usepackage{amsmath}
\usepackage{amssymb}
%\usepackage{multirow}
\usepackage{url}
\begin{document}

\title{Source detection in astronomical images by Bayesian model comparison}

\classification{02.70.-c, 42.30.Tz}
\keywords  {Source detection, astronomy, Bayesian model comparison}

\author{Marcus Frean}{
  address={School of Engineering and Computer Science, Victoria University of Wellington}
}

\author{Anna Friedlander}{
  address={School of Engineering and Computer Science, Victoria University of Wellington}
}

\author{Melanie Johnston-Hollitt}{
  address={School of Chemical and Physical Sciences, Victoria University of Wellington}
}

\author{Christopher Hollitt}{
  address={School of Engineering and Computer Science, Victoria University of Wellington}
}

\begin{abstract}
The next generation of radio telescopes will generate exabytes of data on hundreds of millions of objects, making automated methods for the detection of astronomical objects (``sources") essential. Of particular importance are faint, diffuse objects embedded in noise. There is a pressing need for source finding software that identifies these sources, involves little manual tuning, yet is tractable to calculate.  We propose a novel image discretisation method that incorporates uncertainty about how an image should be discretised. We then suggest a new objective function, based on marginalising over the Dirichlet-multinomial distribution, which indicates how well a given region conforms to a well-specified model of background compared to a loosely-specified model of foreground. This enables Bayesian model comparison to find regions that differ from the background distribution. We iteratively improve the model of background by removing found sources from the data. We evaluate the objective function on identifying sources in real and simulated data. Our approach performs well on these measures: the Dirichlet-multinomial ratio is maximized at most real objects, while returning only a moderate number of false positives. In comparison to a catalogue constructed by widely-used source detection software with manual post-processing by an astronomer, our method found a number of dim sources that were missing from the ``ground truth" catalogue. %This is a key success of the objective function: dim objects are scientifically interesting and not reliably found by current methods.
\end{abstract}

\maketitle

% Body of paper goes here. Use proper sectioning commands. 
% References should be done using the \cite, \ref, and \label commands
%\section{Source detection in radio astronomy}

The sheer scale of data generated by next-generation radio telescopes makes automated methods for finding astronomical objects essential. However, existing approaches require time-intensive manual parameter tuning, and manual post-processing by an astronomer, and are not fully adequate to find all objects of interest \cite{hollitt2012feature, norris2011emu, norris2012radio}.

%Current algorithms are not fully adequate to find all objects of interest. Faint and spatially extended sources are poorly handled by existing automated approaches, as are sources in the presence of artefacts, and in images in which the signal-to-noise ratio varies 

% \subsection{Existing approaches to source detection}
Most automated source detection algorithms can be described
as flood-filling or region-growing, driven by (possibly transformed)
pixel intensities \cite{masias2012review}.  These often require 
restricting the sources to those that are at least as bright as some
threshold, typically set at $3 \sigma$ or $5 \sigma$ above root mean
square (rms) noise. However, some of the most scientifically important
objects in astronomy are dim, low surface brightness sources, with
intensities in the range of background noise \cite{norris2011emu}.

There are a small number of Bayesian source detection algorithms (reviewed in \cite{masias2012review}), most of which use Markov-chain Monte Carlo sampling (MCMC) to estimate the relative probability that each pixel (or pixel grouping) in an image arises from background or is a source pixel \cite{feroz2008multimodal, masias2012review}. For examples, see \cite{savage2007bayesian}, \cite {carvalho2009fast}, and \cite{guglielmetti2009background}.  

The work most similar to that in this paper is that of Hobson and McLachlan \cite{hobson2003bayesian}, who performed Bayesian model selection using MCMC to explore the parameters of background and source models, with a source model of circularly symmetric Gaussian-profile objects and a background model of Gaussian noise. 
%They present two versions of the algorithm: one in which all sources are found simultaneously, and one in which sources are found iteratively. 
Brewer \textit{et. al.} \cite{brewer2013probabilistic} have successfully scaled a model similar to Hobson and McLachlan's \cite{hobson2003bayesian} up to $\sim 1000$ sources.

In contrast to the existing Bayesian source detection methods, in our procedure source and background are modelled as distributions over ranges of pixel intensities. We first show how to avoid the worst problems caused by naive binning procedures. In common with other approaches we then assume a parametrised form (shape) for astronomical sources and find the most plausible shape parameters per source, however sources are not assumed to be circularly symmetric or of a particular size, and we make only weak assumptions about the form of the noise distribution. By exploiting the relative consistency of image background, we suggest a tractable way to infer the probability that a given region is source or background, avoiding the difficulties in approaches based on comparing to ``typical'' exemplars of each. This leads to an objective function which, when maximized, finds sources. Instead of MCMC, we make use the analytic integral over histograms that is possible via the Dirichlet-multinomial distribution.

%We build Dirichlet and multinomial models for pixel intensity distributions in radio astronomy images, and to use these to find sources. 

\section{Discretisation by binning}\label{sec:binning-strategies}

Radio astronomy images have continuous-valued pixel intensities, which can be converted to a smaller set of discrete values or ``bins'' \cite{yang2010discretization}.
A histogram of pixel intensities can be constructed by assigning each pixel in an image to a bin on the basis of its intensity, where bins are ranges of intensity values. % defined as $[min_k, max_k)$. 
%A pixel $x$ falls into bin $k$ if $min_k \le x < max_k$ (except in the case of the last bin $K$, which is defined as $[min_K, max_K]$: a pixel $x$ is assigned bin $K$ if $min_K \le x \le max_K$). For adjacent ranges $[min_i, max_i)$ and $[min_j, max_j)$, $max_i \le min_j$ and so each data instance falls into exactly one bin; coverage is ensured by setting $min_j = max_i$.
%
%In order to discretise intensity values by histogram binning, bin borders (values that define $min_k$ and $max_k$ for each bin $k \in K$) must be defined. 
The number of bins must also be set (either manually, or by the binning method itself). %A simple way to create bins in data is to partition the data on the basis of either interval-width or bin-occupancy.
%Width-based methods divide the number-line between $x_{min}$ and $x_{max}$ where $x_{min}$ is the minimum pixel intensity value in the data, and $x_{max}$ is the maximum value \cite{yang2010discretization}. 
The simplest way to partition data into bins is to create $K$ equal width partitions in the data range \cite{yang2010discretization}.
%The width of intervals is defined as $w = (x_{max} - x_{min})/K$, and the bin are defined at $[x_{min}, x_{min}+w), [x_{min}+w, x_{min}+2w), .. ,[x_{min}+(K-1)w,x_{max}]$. This is an equal partitioning of the number-line between $x_{min}$ and $x_{max}$.
Alternatively, bins may be defined according to their occupancy, by
ranking the data and assigning partitions based on this ranking
\cite{yang2010discretization}.  Equal occupancy partitions are
constructed by dividing the $N$ ranked pixels evenly into $K$ bins, and
thereby arriving at the corresponding bin ranges.

% \subsection{A novel method for softening bin borders}\label{sec:dirichlet-borders}

There are three major problems with the simple discretisation/binning methods for radio astronomy data: there is a lack of any informed basis for deciding on what bin boundaries to use and so any particular choice amounts to an unjustified assertion; because radio astronomy data is non-uniform, relevant groupings of values may be split across bins or combined in bins in a way that reduces discriminative power \cite{clarke2000entropy}; discretisation results in sudden changes at partition values, which introduces variation into the system that did not previously exist --- moreover, data-points that lie near a boundary of a bin are less well represented by that bin than data-points that lie towards the middle of the bin's interval \cite{yang2002non}.

%Given that there is a lack of any informed basis for the choice of bin boundaries used, and the problems inherent in binning non-uniform data, 
It would be more principled to assign proportions of each pixel across a range of bins to reflect uncertainty about which bin a pixel belongs to.
Instead of making a ``hard" assignment of pixels to bins,
% where each pixel is allocated to one bin only
we create many sets of bins $b \in B$, each of size $K$, with bin sets $b_i$ and $b_j$ having differing partition points. Each pixel then has a number of ``possible" bin assignments across sets of bins.
% (each pixel $x$ will fall into one bin $k$ for each set of bins $b$).
%Given a number of plausible sets of bins $B$, 
By using set of bin boundaries, 
%We can then count how often a given pixel $x$ appears in each bin $k \in B$. Once normalised (by dividing the counts in each bin by the number of $b \in B$, so that the sum of counts for each pixel $x$ across bins is equal to $1$) this gives 
we have a {\it distribution} over all the bins for each pixel, reflecting our uncertainty about where the borders should lie.
This solves the problem of the sudden changes at bin borders, and is a method for converting continuous values into distributions over discrete values (counts). It reduces the impact both of the uninformed choice of bins and of any within-class splitting over bins and between-class combining within bins \cite{clarke2000entropy}.

We use the Dirichlet distribution \cite{frigyik2010introduction,hoadley1969compound,ng2011dirichlet}, parametrized by $\boldsymbol{\alpha} = \alpha_1,...,\alpha_K$, to create sets of bins.
%, as it is a probability density function on the ($K-1$) dimensional simplex:
%\begin{align}
%f(p_1, ..., p_{K-1};\alpha_1,...,a_K)=\frac{\Gamma(\sum_{i=1}^K \alpha_i)}{\prod_{i=1}^K \Gamma(\alpha_i)}\prod_{i=1}^K p_i^{a_i-1} \label{eq:dir-pdf}
%\end{align}
%where $\Gamma(.)$ denotes the gamma function; and with $p_i \in [0,1]$, $\sum_{i=1}^{K-1} p_i < 1$, and $p_K = 1 - p_1 - ... - p_{K-1}$ 
A single sample from a Dirichlet distribution
yields a $K$-element vector $\mathbf{p}$ for which $\sum_{k=1}^K p_k =
1$ and all $p_k > 0$ (such as $\mathbf{p}=[0.1,0.7,0.2]$ with
$K=3$). The cumulative sum of the elements of $\mathbf{p}$, denoted
$\mathbf{p}_d$, can be interpreted as the break-points of a partition
over $[0,1]$. % (such as $\mathbf{p}_d = [0.1,0.8,1.0]$).

To translate $\mathbf{p}_d$ into bins, these partitions can either be
interpreted over the number-line between minimum and maximum pixel
values $[x_{min}, x_{max}]$ or over a ranking of pixels.  A Dirichlet
distribution with symmetric $\boldsymbol{\alpha}$ vector ($\alpha_i
= \alpha_j > 1 \; \forall i,j$) will produce roughly equal values for
all $p_k \in \mathbf{p}$, and the larger the $\alpha$ values, the more
uniform the distributions drawn. Draws from a Dirichlet distribution
with such an $\boldsymbol{\alpha}$ vector can be used as partition
points in a set of roughly equal width or roughly equal-occupancy
bins.

\begin{figure}[hbt]
\centering
\includegraphics[width=0.9\textwidth]{eqdir-binned-score.png} 
\caption{\textbf{Exhaustive calculation of DMR} on simulated data over $x$ and $y$ positions $\theta = (m_x, m_y)$ with parameters $\sigma_x$,  $\sigma_y$ and $\phi$ kept constant. From left to right: three simulated sources; the image overlaid with Gaussian noise; the noisy image binned with Dirichlet equal occupancy bins; DMR over $(m_x,m_y)$ calculated using these bins, shown using a colour gradient from red (background) to blue (source). All three sources are recovered. The blue peaks in function-space for two of the three sources in the image at right indicate high values for these sources, and roughly equal values despite the bottom source being brighter than the top one. The objective function's value for the dim source is relatively lower than that for the other two sources, however it still exceeds a value that would indicate ``background", relative to the true background regions.} 
\label{fig:eqdir-binned-score}
\end{figure}

\section{Source detection} 
Given an astronomical image and a generative model for the
distribution of background pixels, a likelihood can be assigned to a
particular region of that image, reflecting how well the region
conforms to the model. If, in addition, there is a model for
foreground, a comparison of the likelihoods can indicate which of the
two best fits the region.

A simple way to do this would be to use categorical distributions
(i.e. simple histograms) for both models. However, while background is relatively
consistent, every source is different: given this variability
what is the best categorical distribution to use? The choice makes a
great difference in the subsequent comparison of likelihoods, yet it
is not obvious what the ``best'' categorical distribution would be.
Instead, we suggest the use of a Dirichlet-multinomial distribution,
which is a generative model for categorical distributions. This
enables us to represent the variability in sources and yet make a
consistent comparison against a (much less variable) model of
background.  We do this by the log of the ratio of posterior
probabilities of two models, which amounts to a 'score' that we denote
DMR (Dirichlet Multinomial Ratio) for brevity.  The task of locating sources
becomes one of optimization of parameters in DMR controlling source
location and shape, which we achieve using gradient ascent.

Within any given region in an image, a histogram of counts \textbf{n} in $K$ bins can be formed, with $b_{x,y}$ the index of the bin that results from the pixel intensity at point $(x,y)$ in the image.
We define the variable $C^{x,y}_k =\delta_{b_{x,y},k}$ where $\delta_{i,j}=1$ {\it iff} \, $i=j$, and is zero otherwise, and therefore the aggregated bin counts for some region $\mathbf{R}$:
\begin{align}
n_k^{(\theta)} &= \sum_{(x,y) \in R} C^{x,y}_k
\end{align}
where $\delta_{i_{x,y},j}=1$ {\it iff} \, $i=j$ (that is, if pixel $i$ at position $(x,y)$ falls into bin $j$), and is zero otherwise. Here $C$ is an indicator variable 
representing the bin index $b$ of the pixel at position $(x,y)$ as a vector consisting of a single 1 (corresponding to $b_k$, the index of the bin $k$ that contains pixel $(x,y)$) and $K-1$ many 0's. 

For two dimensional data, a region in an image with ``soft'' borders can be defined by a weighting function $W^{\theta}_{x,y}$ over points $(x,y)$, with
parameters $\theta$ specifying the position and shape of the region.
We specify a Gaussian elliptical region with parameters $\theta =$ center coordinates $m_x$ and $m_y$, approximate half-widths in orthogonal direction $\sigma_x$ and
$\sigma_y$, and rotation parameter $\phi$. 
The weighting function is defined \cite{rencher2003methods}:
\begin{align}
f &= \exp\left(- \;\left(a\Delta_x^2+2b\Delta_x\Delta_y+c\Delta_y^2 \right) \right)\label{eq:region-weight-in-2d-simpl} \\
\text{where} \;\;\;\;\;\;\;\;\;\;\;
%\intertext{where $\Delta$ signifies a displacement from the central position,}
\Delta_x &= x-m_x, \;\;\;\;\text{and} \;\;\; \Delta_y = y-m_y  \label{eq:Delta-defn}  \\
\text{with:} \;\;\;\;\;\;\;\;\;\;\;\;\;\;
a &= \frac{\cos^2(\phi)}{2\sigma_x^2} + \frac{\sin^2(\phi)}{2\sigma_y^2} \label{eq:a-wgt} \\
b &= \frac{-\sin(2\phi)}{4\sigma_x^2} + \frac{\sin(2\phi)}{4\sigma_y^2} \label{eq:b-wgt} \\
c &= \frac{\sin^2(\phi)}{2\sigma_x^2} + \frac{\cos^2(\phi)}{2\sigma_y^2} \label{eq:c-wgt}
\end{align}

The aggregated bin counts in a region obtained using any histogram binning strategy (including the ``soft'' method described earlier) can be multiplied by the weighting function to give ``weighted counts'', $\hat{C}$:
\begin{align}
\hat{C}^{x,y}_k &= C^{x,y}_k  \; W^{\theta}_{x,y}
\end{align}
(to avoid clutter, $\hat{C}$'s dependence on $\theta$ is omitted). The aggregated bin counts for the region defined by $\theta$ are then:
\begin{align}
n_k^{(\theta)} 
&= \sum_{x,y} \; \hat{C}^{x,y}_k  \label{eq:soft-bin-counts-2d} 
\end{align}

%\subsection{Scoring a region: a Dirichlet-multinomial objective function and its gradient}\label{sec:dir-score}

% The Dirichlet-multinomial distribution is a compound probability distribution, where the parameter vector $\textbf{p} = p_1, ..., p_K$ of a multinomial distribution (with the probability that value $k$ is drawn from $\textbf{p}$ given by $p_k$), is drawn from a Dirichlet distribution with parameter vector $\boldsymbol\alpha = \alpha_1, ..., \alpha_K$ \cite{ng2011dirichlet}.

For some vector of counts $\textbf{n}^{(\theta)}$ in $K$ bins of a histogram (where the counts are taken within a region defined by $W^{(\theta)}$), integrating out the multinomial distribution gives the following marginal joint likelihood in terms of hyperparameter $\boldsymbol{\alpha}$ \cite{ng2011dirichlet}:
\begin{align}
P(\textbf{n}^{(\theta)}|\boldsymbol{\alpha}) &= \frac{\Gamma(A)}{\Gamma(N+A)} \prod_k \frac{\Gamma(n_k+\alpha_k)}{\Gamma(\alpha_k)}  \label{eq:muldir} 
\end{align}
where $\Gamma(.)$ denotes the gamma function, $A = \sum_k \alpha_k$ and $N = \sum_k n_k$. 
%% Taking logs,
%% \begin{align}
%% \log P(\textbf{n}^{(\theta)}|\boldsymbol{\alpha}) = \log \Gamma(A) - \log \Gamma(N+A) \notag\\
%% + \sum_k \log \Gamma(n_k+\alpha_k) - \log \Gamma(\alpha_k) \label{eq:logmultdir}
%% \end{align}

%% A good objective function should give an indication of how poorly a histogram of pixel intensities in a particular region (that is, binned counts) conforms to a model of background, where the model is histograms that might be expected in regions of pure ``background'' signal. (Or alternatively, how poorly a region's histogram conforms to a model of background as compared to how well it conforms to a model of foreground).

An objective  function can be derived from the ratio of posterior probabilities \cite{kass1995bayes} under these two models:
\begin{align}
\text{DMR}(\theta) 
%&= \log \frac{P(S | \textbf{n}^{(\theta)})}{P(B | \textbf{n}^{(\theta)})} \label{eq:score} \\
&= \log \frac{P(\textbf{n}^{(\theta)} | S)}{P(\textbf{n}^{(\theta)} | B)} \;\; + \; \log \frac{P(S)}{P(B)}\label{eq:score2}
\end{align}
where $S$ denotes the Dirichlet-multinomial distribution with hyperparameter vector $\boldsymbol{\alpha}^S$ and similarly for $B$ with $\boldsymbol{\alpha}^B$.
% Marcus: THIS PHRASING / NOMENCLATURE ISN'T QUITE CORRECT IS IT. AWKWARD. 
% Anna : no, it's fine.
To reflect the prior belief that radio astronomy images are dominated
by background, a heuristic value for the prior for the ratio of source
to background pixels in the image may be used in place of the second
term. We use a ratio of $0.05 : 0.95$.

We can also find the gradient of this objective function with respect to the region parameters, $\theta$. Denoting the derivative of the log of the $\Gamma$ function by $\psi$, the overall gradient is \cite{AnnaThesis}:
%% \begin{align}
%% \log {P(\textbf{n}^{(\theta)} | S)} - \log {P(\textbf{n}^{(\theta)} | B)} \notag\\
%% = \sum_k \log \Gamma (n_k + \alpha^S_k) - \log \Gamma (N + A^S) \notag\\
%% - \sum_k \log \Gamma (n_k + \alpha^B_k) + \log \Gamma (N + A^B) \label{eq:dirmult-score}
%% \end{align}
%% \begin{align}
%% \frac{\partial}{\partial\theta}\text{DMR}(\theta) 
%% = \sum_k [\underbrace{\psi(n_k + \alpha^S_k) - \psi(n_k + \alpha^B_k)}_{\text{denote} \; Q_k}] \frac{\partial n_k^{(\theta)}}{\partial\theta} \notag\\
%%  - \;\;\; [\psi(N+A^S) - \psi(N+A^B)]\sum_k \frac{\partial n_k^{(\theta)}}{\partial\theta}\\
%% = \sum_k  Q_k \, \frac{\partial n_k^{(\theta)}}{\partial\theta}\;-\;
%% \sum_k
%% \underbrace{ [\psi(N+A^S) - \psi(N+A^B)}_{\text{denote} \; Q_\text{base}}] \frac{\partial n_k^{(\theta)}}{\partial\theta}\\
%% = \sum_k (Q_k - Q_\text{base}) \; \frac{\partial n_k^{(\theta)}}{\partial\theta} \label{eq:score-grad-1d}
%% \end{align}
\begin{align}
\frac{\partial}{\partial\theta}\text{DMR}(\theta) 
&= \sum_k (Q_k - Q_\text{base}) \; \frac{\partial n_k^{(\theta)}}{\partial\theta} 
\end{align}
\begin{align*}
\text{where} \;\;\;\;\;\;\;\;\;\;\;\;\;\;
Q_k &= \psi(n_k + \alpha^S_k) - \psi(n_k + \alpha^B_k)   \\
Q_\text{base} &= \psi(N+A^S) - \psi(N+A^B)
\end{align*}
The remaining gradient term can then be calculated \cite{AnnaThesis} from Equation \ref{eq:soft-bin-counts-2d}. Writing $f = \; \log W^{\theta}_{x,y}$, this is:
\begin{align}
\frac{\partial n_k^{\theta}}{\partial\theta} %&= \sum_{x,y} \, C^{x,y}_k \; \frac{\partial W^{\theta}_{x,y}}{\partial\theta} \\
&= \sum_{x,y} \, C^{x,y}_k \;  W^{\theta}_{x,y} \; \frac{\partial f}{\partial\theta} 
%&= \sum_k (Q_k - Q_\text{base}) \; \sum_{x,y} \hat{C}^{x,y}_k \;\; \frac{\partial f}{\partial\theta}
\label{eq:general-gradient}
\end{align}

\begin{figure}
\includegraphics[width=0.9\textwidth]{1d-score-egs3.png}
\caption{\textbf{Exhaustive calculation of DMR and its gradient} over $m \in [0..500]$ and $\sigma \in [0..250]$. Three sources have parameter $m = (145, 275, 354)$. The three subplots correspond to: a plot of the data (black dots) with blue lines at the location of bin borders; a plot of the binned data (blue square dots); the function space with parameter $m$ on the $x$-axis and $\sigma$ on the $y$-axis. DMR is shown via the background colour, and its gradient as black lines.
% Each point in the space is coloured along a continuum indicating whether background or source is favoured. Gradient lines (black) are superimposed.
} 
\label{fig:1d-score-egs3}
\end{figure}

\section{Methods}
\begin{figure}[Hhbt]
\includegraphics[width=0.48\textwidth]{comparisons.png}
\caption{\textbf{Comparison with the ground truth catalogue.} {\it Top left:} A section of one of the CDFS test-windows with a low brightness source (radio galaxy tail; pink ring). Note also the two separate sources in the blue ring. {\it Top right:} sources identified by BLOBCAT (raw, unprocessed output). {\it Lower left:} sources in the ground-truth catalogue, and ({\it lower right)} found by the DMR algorithm. DMR has identified all the sources in the ground truth catalogue, and, in addition has found part of the radio galaxy tail missing from the ground truth catalogue. It has also correctly identified two separate sources that the ground truth catalogue conflated (blue ring). %, although one of DMR's width parameters for the upper source is incorrect.
} 
\label{fig:comps}
\end{figure}
The performance of the objective function in identifying astronomical sources was evaluated against simulated and real data.

Real data comprised 25 randomly selected $500 \times 500$ pixel windows of two large astronomical images\footnote{Australia Telescope Large Area Survey European Large Area ISO Survey S1 and Australia Telescope Large Area Survey Chandra Deep Field-South \cite{norris2006deep}.}. Each window was treated as a whole image for purposes of evaluation of DMR; windows had an average of $36$ sources each.% (see Table \ref{table:2d-info}). 
``Ground truth" sources and their parameters (central position and coordinates describing a bounding box around each source) were identified using the source-finding package BLOBCAT \cite{hales2012blobcat} with manual postprocessing by an astronomer. Noisy borders of the images were excluded from source detection in construction of the ground truth catalogue.\footnote{The area of the two images for source extraction was defined by: rms noise $\le 100 \mu$ Jy beam$^{−1}$; bandwidth smearing $ \ge 80\%$; and mosaicked primary beam response $\ge 40\%$. The defined area covers $3.566$ square degrees of the CDFS image $2.697$ square degrees of the ELAIS image \cite{banfield2013australia}.} BLOBCAT was restricted to finding sources at least $4 \sigma$ above rms noise, and the final catalogue was restricted to sources at least $5 \sigma$ above rms noise. For pixel-intensity based thresholding methods such as BLOBCAT, search must be restricted in this way to avoid identifying background regions as sources. However, some of the most scientifically important objects in astronomy are those that are dim, with intensities in the range of background noise \cite{norris2011emu}. The DMR does not restrict search in this way.
%\begin{table}
%\begin{tabular}{l c c c c}
%\hline
%  & \tablehead{1}{c}{b}{ELAIS\tablenote{Australia Telescope Large Area Survey European Large Area ISO Survey S1 \cite{norris2006deep}}}   
%  & \tablehead{1}{c}{b}{CDFS\tablenote{Australia Telescope Large Area Survey Chandra Deep Field-South \cite{norris2006deep}}} \\\hline
%\# ``ground truth" sources   & 2067         & 3079        \\
%\# sub-windows used          & 13           & 12          \\
%Mean (std dev) sources/window & 34.7 (11.7)  & 37.2 (8.7)  \\
%Min, max sources/window       & 16, 53       & 20, 49      \\\hline
%\end{tabular}
%\caption{Astronomical images used for evaluation}
%\label{table:2d-info}
%\end{table}

Simulated images were created by generating three ``sources" using the Gaussian ellipse function (Equation \ref{eq:region-weight-in-2d-simpl}), and 
%% Simulated data were created by generating three ``sources", generated using the Gaussian ellipse function (with center coordinates $m_x$ and $m_y$, approximate half-widths in orthogonal direction $\sigma_x$ and $\sigma_y$, and rotation parameter $\phi$, and $A$ controlling the height of the peak),
%% \begin{align}
%% A\exp\left(- \;\left(a(x-m_x)^2+2b(x-m_x)(y-m_y)+c(y-m_y))^2 \right) \right)\label{eq:2d-testregion}
%% \end{align}
%% with $a$, $b$ and $c$ defined as per Equation \ref{eq:region-weight-in-2d-simpl}. 
overlaying them with zero-mean Gaussian noise (fixed-variance with the same variance of background pixels for one source, variance that increases proportionally with the height of the source for another source, and such that faint sources have lower than average variance for the third source). 

The images were discretised using equal occupancy and equal width bin border strategies with $K=10$. The Dirichlet-border ``softening" of both types of bin borders was also used with a symmetric $\boldsymbol{\alpha}$ vector with $\alpha_i = 10 \; \forall i$, and generating $50$ sets of bins.

% \subsection{Derivation of $\boldsymbol{\alpha}^S$ and $\boldsymbol{\alpha}^B$}\label{sec:alphas}
DMR compares the binned counts in a region with theoretical ``background" and ``source" distributions via the $\boldsymbol{\alpha}$ vectors of Dirichlet distributions from which multinomial distributions over bins for ``background" and ``source" distributions are drawn.
% Obviating the need for manual selection of a ``typically background" region, the whole image may be used as the $\boldsymbol{\alpha}^B$ vector. That is, the image is binned according to a particular binning strategy, and the binned-counts are used as the $\boldsymbol{\alpha}^B$ vector. This is particularly appropriate for astronomical images in which background pixels far outnumber source pixels --- in any particular background region, one would expect relatively few source pixels. 
We set the source model $\boldsymbol{\alpha^S}$ to the symmetric
$\boldsymbol{\alpha}$ vector with $\alpha_i = \alpha_j = 1 \; \forall
i,j \in 1,...,K$, which is non-committal about what a source
distribution might be, and $\boldsymbol{\alpha^B}$ to be the binned-counts of the whole image. %: all multinomial distributions over $K$ bins are equally likely to be drawn from the Dirichlet distribution with this $\boldsymbol{\alpha}$-parameter \cite{frigyik2010introduction}.
Given these parameterisations for $\boldsymbol{\alpha}^B$ and $\boldsymbol{\alpha}^S$, background regions are expected to have a similar distribution over bins as the whole image does; while a source region may have any distribution over $K$ bins. A high DMR value using Equation \ref{eq:score2} means that the counts \textbf{n} in a region are highly dissimilar to those expected under multinomial distributions drawn from a Dirichlet distribution having parameter vector $\boldsymbol{\alpha}^B$. So, for example, a region in which there is a higher proportion of bright pixels than is typical in the image would receive a high DMR value. More generally, regions in the image with \textit{any} ``unusual" distributions across bins will correspond to peaks in the function.

%This broad definition of non-background like regions in an image allows a great deal of flexibility in the use of DMR to find different types of features in astronomical images.

%\subsection{Gradient ascent}\label{sec:grad-asc-1d}
The gradient of the objective function was calculated using the Gaussian function parametrisation of the window function $W^{(\theta)}$ (Equation \ref{eq:region-weight-in-2d-simpl}) for a test region. A bounded Newton Conjugate-Gradient algorithm 
%from the Python package \texttt{scipy.optimize} 
\cite{scipy} was used to implement gradient ascent. 

One ``round" of source-finding consisted of 50 trials of gradient ascent for simulated data, and just one trial of gradient ascent for real data (to speed up execution). To save computational time and make use of the domain knowledge that sources are brighter than background, initial values for parameters $m_x, m_y$ were set to the coordinates of the brightest pixel in the image, with random initial values for $\sigma_x$, $\sigma_y$, and $\phi$.

The peak with the highest value in each round was recorded as a found source, and removed from the data. After each source removal, histogram bin borders and the $\boldsymbol{\alpha}^B$ vector were re-calculated on the remaining data. 

For simulated data, three rounds were performed per image. For real data, rounds of gradient ascent continued until the maximum DMR found was negative
% IS THAT RIGHT? Was: ``had a value that indicated it was more likely to be background than source''
or after $53$ rounds (the maximum number of sources in any window), whichever came first.

% \subsection{Evaluation methods}
Because the test regions are continuous in the image, for the purposes of evaluation the region of a found source is restricted to the ellipse defined by the parameters $\theta = (m_x, m_y, 2\sigma_x, 2\sigma_y, \phi)$. This is equal to $95$ per cent of the area under the curve generated by the Gaussian function \cite{wasserman2004all}.

In the case of real data, ``true sources" were those identified by the source-finding package BLOBCAT \cite{hales2012blobcat} with manual postprocessing by an astronomer. These sources have parameters describing a ``bounding box" around the source. Precision and recall \cite{olson2008advanced} were calculated in order to evaluate performance. %Precision is the proportion of true sources of all found sources (that is, all found sources that are really sources): $\text{precision} = \frac{\textbf{tp}}{\textbf{tp}+\textbf{fp}}$ and recall is the proportion of found sources of all true sources in the image (all true sources that are found): $\text{recall} = \frac{\textbf{tp}}{\textbf{tp}+\textbf{fn}}$ where $\textbf{tp} =$ ``true positive", $\textbf{fp} =$  ``false positive", and $\textbf{fn} =$ ``false negative" \cite{olson2008advanced}.
A true positive occurs when the location of at least $50$ per cent of a found source's pixels overlap with at least $50$ per cent of a real source's pixels. A false positive is a found source that does not meet these criteria, a false negative is a true source that does not meet these criteria. 

\section{Results and discussion}\label{sec:results}
\begin{table}
\centering
\begin{tabular}{l c c}
\hline
    \tablehead{1}{c}{b}{Binning method}
  & \tablehead{1}{c}{b}{Simulated data\tablenote{For simulated data, because there are three sources per image, and three rounds of gradient ascent producing three found sources per image, precision $=$ recall.}}
  & \tablehead{1}{c}{b}{Real data} \\\hline
Equal width               & 0.83, 0.83 & 0.51, 0.74 \\
Dirichlet equal width     & 0.57, 0.57 & 0.59, 0.75 \\
Equal occupancy           & 0.79, 0.79 & 0.30, 0.30 \\
Dirichlet equal occupancy & 0.84, 0.84 & 0.32, 0.34 \\\hline
\end{tabular}
\caption{Performance of the DMR: precision, recall.}
\label{table:2d-real-res}
\end{table}

Figure \ref{fig:eqdir-binned-score} illustrates an exhaustive calculation of DMR on simulated data over $x$ and $y$ positions $\theta = (m_x, m_y)$ with other parameters kept constant. The positions of the original sources are recovered almost perfectly, despite the fact that they are obscured with noise.

Figure \ref{fig:1d-score-egs3} shows an exhaustive calculation of DMR and its gradient on a one dimensional $1 \times X$ ``slice" through an astronomical image (ATLSB survey region A at $50"$ resolution \cite{saripalli2012atlbs,subrahmanyan2010atlbs}), using Dirichlet equal width bins and a one dimensional Gaussian region, with centre and half-width parameters $\theta = (m, \sigma)$. High DMR values correspond to the location of sources, while the rest of the image has values that tend strongly towards the background model. Gradient lines converge at the peaks of the regions of values indicating sources.

Performance of DMR is given in Table \ref{table:2d-real-res}.

%Results obtained using equal occupancy binning (with and without Dirichlet softening of bin borders) are very low, in comparison both to results obtained on simulated data, and equal width results on real data. This may possibly be attributed to the source finding process, in which each round of gradient ascent is initialised at a bright point in the data, and finishes with the removal of the found source and recalculation of the $\boldsymbol{\alpha}^{B}$ vector and bin borders. For radio astronomy data where the vast majority of pixels fall into a low intensity range with a small number of bright outliers, this process lends itself to equal width binning strategies. In such strategies, the brightest pixels will be binned alone; iterative removal of these pixels and recalculation of the bins will reveal the next brightest pixels, and so on.
% 
%With the equal width binning strategies, the precision and recall of DMR on the real two dimensional data is lower than the results on the simulated one dimensional and two dimensional data. Though the rate of recall is good ($0.74$ and $0.75$), precision, in particular, is very low ($< 0.6$) on the full set of sources found. 
% 
Low precision of the DMR on real data can be partly explained by the fact that DMR found more sources than appear in the ground truth catalogue. While some of these additional found sources are spurious, some do appear to be sources that were missed by BLOBCAT with manual postprocessing. This is not surprising given that the ground truth catalogue only contained sources at least $5 \sigma$ above rms noise, while DMR was not restricted in this way. In fact, even the raw BLOBCAT output (without manual postprocessing) had precision of only $0.69$ when compared to the ground-truth catalogue. Examples of found sources that were not found by BLOBCAT and are not in the ground truth catalogue can be seen in Figure \ref{fig:comps}.

%\section{Conclusions and future work}
Some of the most scientifically important objects in astronomy are dim, with intensities in the range of background noise \cite{norris2011emu}. The nature of pixel-intensity based thresholding algorithms such as BLOBCAT restricts their ability to find such dim sources without also finding such a large number of noise regions that the results are unusable. 

The implementation described here is a preliminary exploration, but encouraging. The DMR algorithm does not restrict the objects found on the basis of some threshold above rms noise, and produces raw results containing most real objects (including dim sources that are not well found by other other algorithms), while returning only a moderate number of false positives in regions of noise.

%The current implementation is unnecessarily slow, due to the fact that we did not truncate the ``window'' function, so counts need to be acquired from the whole image at all updates. Another issue is that the iterative removal of found sources sometimes leaves artefacts around the removed source, which can cause multiple ``found sources" where in fact only one source lies. Finally, the $\boldsymbol{\alpha}^S$ vector of DMR was set to the symmetric $\boldsymbol{\alpha}$ vector with $\alpha_i = 1$, in order to give equal likelihood to all multinomial distributions over $K$ for source regions (so that source regions were defined as ``non-background"). It would be useful to explore ways of setting the $\boldsymbol{\alpha}^S$ vector such that particular distributions are favoured over others.

%Though further development of the objective function is needed, our approach is in many cases better at finding scientifically important dim sources. It is approaching a usable algorithm that does not require the intensive manual parameter tuning of existing algorithms. 

% --- the need for source finding software with a minimum of manual tuning is pressing, given the huge volumes of data to be produced by the next generation of radio astronomy telescopes \cite{norris2011emu}.


%A significant drawback of the implementation described in this paper however, is that the gradient ascent process was too slow to be practical (or even possible) on full-sized images. Future work to improve this is needed. One aspect that could be improved to speed up this process is the use of a test region with finite support. The use of a Gaussian distribution for test regions mean that regions extend potentially across the whole image, slowing down the gradient ascent process. This was also an issue for at least one other Bayesian source detection algorithm \cite{feroz2008multimodal} for which investigation into alternative distributions to the Gaussian is ongoing. 

%An issue with the process within which DMR is used in this paper is that the iterative removal of found sources sometimes leaves artefacts around the removed source. This can cause multiple ``found sources" where in fact only one source lies. Addressing this issue may reduce the number of false positives caused by multiple found sources on one true source.

%The second term in DMR (Equation \ref{eq:score2}) weights the likelihood of a region being source or background by the relative proportion of each in the image. This term was set heuristically in this paper, to reflect the prior belief that astronomical images are dominated by background pixels. However, DMR could be extended to incorporate a Dirichlet hyperparameter over the source and background mixing proportions in an image or regions within that image. The mixing proportions could be modelled as a multinomial distribution.

% Create the reference section using BibTeX:
\bibliographystyle{aipproc}
\bibliography{maxent.bib}
\end{document}
%
% ****** End of file aiptemplate.tex ******
